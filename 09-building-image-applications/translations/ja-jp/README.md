# 画像生成アプリケーションの構築

[![Building Image Generation Applications](../../images/09-lesson-banner.png?WT.mc_id=academic-105485-yoterada)](TBD)

> **ビデオは近日公開予定**

LLM はテキスト生成だけでなく、テキストの説明から画像も生成できます。画像生成は、医療や建築、観光、ゲーム開発のように様々な業界において価値が高いとされています。この章では、最も人気のある 2 つの画像生成モデル、DALL-E と Midjourney について詳しく見ていきます。

## はじめに

このレッスンでは、下記の内容について説明します。

- 画像生成の有用性
- DALL-E と Midjourney の概要とその動作原理
- 画像生成アプリの作り方

## 学習目標

このレッスンを修了すると、下記を理解できます：

- 画像生成アプリの作成  
- メタプロンプトを用いてアプリケーションの範囲を定義  
- DALL-E と Midjourney の活用方法

## 画像生成アプリケーションを作る理由は何でしょう？

画像生成アプリケーションは、生成 AI の能力を引き出す絶好の手段です。例えば、下記のような用途に利用できます：

- **画像編集と合成**：画像編集や画像合成など、様々な用途の画像を生成できます。

- **多種多様な業界への応用**：医療技術、観光、ゲーム開発など、様々な業界の画像を生成できます。

## シナリオ ： Edu4All

このレッスンでは、引き続きスタートアップの Edu4All で作業を進めていきます。生徒たちは評価用の画像を作成します。具体的にどのような画像を作るかは生徒たち次第ですが、自分たちの創作するおとぎ話のイラストを描いたり、物語の新しいキャラクターを作ったり、自分たちのアイデアや概念を視覚化する手助けをしてくれます。

例えば、Edu4All の生徒たちが授業で記念碑について学んでいる場合、下記のような画像を生成できます：

![Edu4All startup, class on monuments, Eiffel Tower](../../images/startup.png?WT.mc_id=academic-105485-yoterada)

次のようなプロンプトを入力します。

> "早朝の日差しを浴びたエッフェル塔の前に座る犬"

## DALL-E と Midjourney とは何でしょう？

[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-yoterada) と [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-yoterada) は、プロンプトを使って画像を生成できる、特に人気のある画像生成 AI モデルの 2 つです。

### DALL-E

まずは、テキストの説明から画像を生成する生成 AI モデル、DALL-E について見ていきましょう。

> [DALL-Eは、CLIP と Diffused attention という2つのモデルを組み合わせたものです](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-yoterada).  

- **CLIP** は、画像やテキストからデータの数値表現である埋め込みを生成するモデルです。
- **Diffused attention** は、埋め込みから画像を生成するモデルです。DALL-E は画像とテキストのデータセットで訓練され、テキストの説明から画像を生成できます。例えば、DALL-E を使って「帽子をかぶった猫」や「モヒカンヘアの犬」の画像を生成できます。

### Midjourney

Midjourney も DALL-E と同様に、テキストプロンプトから画像を生成できます。Midjourney も同様に、「帽子をかぶった猫」や「モヒカンヘアの犬」などのプロンプトを使って画像を生成できます。

![Image generated by Midjourney, mechanical pigeon](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-yoterada)
*Image cred Wikipedia, image generated by Midjourney*

## DALL-E と Midjourney はどのように動作するのでしょうか？

まず、[DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-yoterada) について説明します。DALL-E は、「*自己回帰型トランスフォーマー*」を用いたトランスフォーマー・アーキテクチャに基づく生成 AI モデルです。

「*自己回帰型トランスフォーマー*」は、AI モデルがテキストの説明から画像を生成する方法を定義します。このモデルは一度に 1 ピクセルずつ生成し、生成したピクセルを使って、次のピクセルを生成します。このプロセスは、画像が完成するまで、ニューラル・ネットワークの複数の層を通過していきます。

このプロセスを通じて、DALL-E は生成する画像の属性、オブジェクト、特性などを制御します。DALL-E 2 や 3 は生成された画像をより詳細に制御する能力を持っています。

## 初めての画像生成アプリケーションの構築

画像生成アプリケーションを作るためには、下記のライブラリが必要です。

- **python-dotenv**：強く推奨：このライブラリを利用し機密情報をコードから分離し「*.env*」ファイルに記述します
- **openai**：OpenAI API を利用するためのライブラリです
- **pillow**：Python で画像を扱うためのライブラリです
- **requests**：HTTP リクエストを作成するのに役立つライブラリです

1. 下記の内容を記述した「*.env*」ファイルを作成します。  
  
    ```text  
    AZURE_OPENAI_ENDPOINT=<your endpoint>  
    AZURE_OPENAI_KEY=<your key>  
    ```  
  
    この情報は、Azure Portal の OpenAI を作成したリソースの「Keys and Endpoints」セクションで確認します。

1. 上記で示した必須ライブラリを「*requirements.txt*」という名前のファイルに記述します

    ```text
    python-dotenv
    openai
    pillow
    requests
    ```

1. 次に、仮想環境を作成し、ライブラリをインストールします

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

    Windows の場合は、下記のコマンドを実行して、仮想環境を作り利用できるようにします

    ```bash
    python3 -m venv venv
    venv\Scripts\activate.bat
    ````

1. 「*app.py*」という名前のファイルに下記のコードを記述します

    ```python
    import openai
    import os
    import requests
    from PIL import Image
    import dotenv
    
    # dotenvをインポート
    dotenv.load_dotenv()
    
    # 環境変数からエンドポイントとキーを取得
    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
    openai.api_key = os.environ['AZURE_OPENAI_KEY']     
    
    # API のバージョンを割り当て（DALL-E は現在、2023-06-01-preview API バージョンのみをサポートしています）
    openai.api_version = '2023-06-01-preview'
    openai.api_type = 'azure'
    
    
    try:
        # 画像生成 API を使用して画像を作成
        generation_response = openai.Image.create(
            prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
            size='1024x1024',
            n=2,
            temperature=0,
        )
        # 画像を保存するディレクトリを設定
        image_dir = os.path.join(os.curdir, 'images')
    
        # ディレクトリが存在しない場合は作成
        if not os.path.isdir(image_dir):
            os.mkdir(image_dir)
    
        # 画像ファイルへのパスを設定（ファイルタイプは png にします）
        image_path = os.path.join(image_dir, 'generated-image.png')
    
        # 生成した画像を取得
        image_url = generation_response["data"][0]["url"]  # レスポンスからイメージの URL を取得
        generated_image = requests.get(image_url).content  # イメージのダウンロード
        with open(image_path, "wb") as image_file:
            image_file.write(generated_image)
    
        # デフォルトの画像ビューアで画像を表示
        image = Image.open(image_path)
        image.show()
    
    # 例外をキャッチ
    except openai.error.InvalidRequestError as err:
        print(err)

    ```

上記のコードについて説明します。

- 最初に、必要なライブラリをインポートします。これには、OpenAI ライブラリ、dotenv ライブラリ、requests ライブラリ、Pillow ライブラリが含まれます。

    ```python
    import openai
    import os
    import requests
    from PIL import Image
    import dotenv
    ```

- 次に、「*.env*」ファイルから環境変数を読み込みます。

    ```python
    # dotenvをインポート
    dotenv.load_dotenv()
    ```

- その後、OpenAI API のエンドポイント、キー、バージョン、タイプを設定します。

    ```python
    # 環境変数からエンドポイントとキーを取得
    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
    openai.api_key = os.environ['AZURE_OPENAI_KEY'] 

    # バージョンと種類を設定、Azure 固有設定
    openai.api_version = '2023-06-01-preview'
    openai.api_type = 'azure'
    ```

- 次に、画像を作成します。

    ```python
    # 画像生成 API を使用して画像を作成
    generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2,
        temperature=0,
    )
    ```

    上記のコードは、生成された画像の URL を含む JSON オブジェクトを返します。このURL を使って画像をダウンロードし、ファイルに保存できます。

- 最後に、画像を開き、標準の画像ビューアを使って表示します。

    ```python
    image = Image.open(image_path)
    image.show()
    ```

### 画像生成の詳細 

画像を生成するコードをさらに詳しく見てみましょう。

```python
generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2,
        temperature=0,
    )
```

- **prompt**：画像を生成するためのテキスト・プロンプトです。この例では、「ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている」というプロンプトを使用しています。
- **size**：生成する画像のサイズを指定します。この例では、1024x1024 ピクセルの画像を生成しています。
- **n**：生成する画像の数です。この例では、2 つの画像を生成しています。
- **temperature**：生成 AI モデルの出力のランダム性を制御するパラメータです。温度は 0 から 1 の間の値で、0 は出力が決定的を意味し、1 は出力がランダムになります。デフォルト値は 0.7 です。

次のセクションでは、画像生成でできる内容についてさらに詳しく説明します。

## 画像生成における追加機能

ここまで、Python コードを実装して画像を生成する方法を見てきました。しかし、画像生成でできる処理は他にもあります。

下記のような処理も可能です。

- **画像編集を行う**：既存の画像にマスクとプロンプトを提供し、画像を編集できます。例えば、画像の一部に、何かを新たに追加できます。たとえばウサギの画像を想像してみてください、ウサギに追加で帽子を被せれます。そのためには、画像、マスク（変更するエリアの部分を特定する）と、何をすべきかを示すテキストプロンプトを提供します。

    ```python
    response = openai.Image.create_edit(
      image=open("base_image.png", "rb"),
      mask=open("mask.png", "rb"),
      prompt="頭に帽子をかぶったウサギの画像",
      n=1,
      size="1024x1024"
    )
    image_url = response['data'][0]['url']
    ```

    ベース画像にはウサギだけが含まれていますが、最終的な画像にはウサギの帽子が含まれています。

- **バリエーションを作成する**：既存の画像を取得し、バリエーションを作成するように依頼します。バリエーションを作成するには、画像とテキストプロンプトを提供し、以下のようなコードを記述します。

    ```python
    response = openai.Image.create_variation(
      image=open("bunny-lollipop.png", "rb"),
      n=1,
      size="1024x1024"
    )
    image_url = response['data'][0]['url']
    ```

    > ご注意：これはOpenAIでのみサポートされています。

## 温度

温度は、生成 AI モデルの出力のランダム性を制御するパラメータで、0 から 1 までの値を取ります。0 は出力が決定的で、1 は出力がランダムになります。デフォルト値は 0.7 になっています。

実際に確認するため、下記のプロンプトを二度実行して、温度がどのように作用するか確認してください。

> プロンプト : "ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている"

![Bunny on a horse holding a lollipop, version 1](../../images/v1-generated-image.png?WT.mc_id=academic-105485-yoterada)

同じプロンプトをもう一度実行し、前回とは異なる画像が出てくるかを確認します

![Generated image of bunny on horse](../../images/v2-generated-image.png?WT.mc_id=academic-105485-yoterada)

ご覧の通り、生成された画像は似ているように見えますが、同じではありません。ここで温度の値を 0.1 に変更して、その結果を見てみましょう。

```python
 generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2
    )
```

### 温度を変更してみましょう

結果をより決定的にしたい場合、生成した二つの画像から見て分かるように、最初の画像にはウサギが、二つ目の画像には馬が映っているので、２つの画像に大きな違いがあります。

そこで、コードを修正して温度を0に設定します。

```python
generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2,
        temperature=0
    )
```

このコードを実行すると、次の二つの画像が得られます。

- ![Temperature 0, v1](../../images/v1-temp-generated-image.png?WT.mc_id=academic-105485-yoterada)
- ![Temperature 0 , v2](../../images/v2-temp-generated-image.png?WT.mc_id=academic-105485-yoterada)

これらの画像をご覧いただくと、２つの画像は明らかに似ています。

## メタ・プロンプトを使ってアプリケーションの範囲を設定する方法

上記のようにして、お客様に提供できる画像を生成できるようになっています。しかし、アプリケーションの範囲を設定する必要があります。

例えば、職場や学校にとって安全でない画像や、子供に適さない画像の生成は避けたいと思います。

これは*メタ・プロンプト*という手法を使って実現できます。メタ・プロンプトは、生成 AI モデルの出力を制御するために使用するテキスト・プロンプトです。例えば、メタ・プロンプトを使って出力を制御し、生成された画像が職場にとって安全か、子供にとって適しているかを確認できます。

### それはどのように動作するのでしょうか？

それでは、メタ・プロンプトはどのように動作するのでしょうか？

メタ・プロンプトは、生成 AI モデルの出力を制御するために使用するテキスト・プロンプトで、テキスト・プロンプトの前に配置し、モデルの出力を制御するために使用します。これはアプリケーションに組み込まれ、モデルの出力を制御します。プロンプト入力とメタ・プロンプト入力を一つのテキスト・プロンプトにまとめます。

メタ・プロンプトの一例を下記に示します。

```text
あなたは子供向けの画像を作成するアシスタントデザイナーです。
 
画像は職場にとって安全で、子供にとって適している必要があります。
 
画像はカラーである必要があります。
 
画像は横長の形式である必要があります。
 
画像は16:9のアスペクト比である必要があります。
 
以下の入力から、職場に安全でない画像や子供にとって適さない画像は除外してください。
 
（入力）
```

さて、それではアプリでメタ・プロンプトをどのように使うか見てみましょう。

```python
disallow_list = "剣、暴力、血、ゴア、ヌード、性的コンテンツ、アダルト・コンテンツ、アダルト・テーマ、アダルト・ワード、アダルト・ユーモア、アダルト・ジョーク、アダルト・シチュエーション、アダルト"

meta_prompt =f"""あなたは子供向けの画像を作成するアシスタントデザイナーです。 

画像は職場の中で使用する際に安全で、子供に適している必要があります。

画像はカラーである必要があります。

画像は横長の形式である必要があります。

画像は16:9のアスペクト比である必要があります。

以下の入力から、職場に安全でない画像や子供にとって適さない画像は除外してください。
{disallow_list}
"""

prompt = f"{meta_prompt} 
ウサギがアメを持って馬に乗っている画像を作成してください"

# TODO 画像生成のリクエストを追加
```

上記のプロンプトは、生成されるすべての画像がメタ・プロンプトを考慮しています。

## 課題 - 学生の能力を引き出しましょう

このレッスンの初めに Edu4All を紹介しました。今度は、学生が自分たちの評価のための画像を生成できるようにしましょう。

学生は、自分たちの評価用の画像を作成します。その画像には記念碑が含まれている必要がありますが、どの記念碑を選ぶかは学生に任せます。学生は、これらの記念碑をさまざまな状況に合わせるために、この課題では創造性の発揮が求められます。

## 解決策

下記に一つの解決策案を示します：

```python
import openai
import os
import requests
from PIL import Image
import dotenv

# dotenvをインポート
dotenv.load_dotenv()

# 環境変数からエンドポイントとキーを取得
openai.api_base = "<エンドポイントに置き換え>"
openai.api_key = "<API キーに置き換え>"     

# APIバージョンを指定（DALL-Eは現在、2023-06-01-preview APIバージョンのみ対応）
openai.api_version = '2023-06-01-preview'
openai.api_type = 'azure'
    
disallow_list = "剣、暴力、血、ゴア、ヌード、性的コンテンツ、大人向けコンテンツ、大人向けテーマ、大人向け言語、大人向けユーモア、大人向けジョーク、大人向け状況、大人"

meta_prompt = f"""あなたは子供向けの画像を作成するアシスタントデザイナーです。
 
画像は、職場において安全で、子供に適している必要があります。
 
画像はカラーである必要があります。
 
画像は横向きである必要があります。
 
画像は16:9のアスペクト比である必要があります。
 
以下の入力は、職場で安全でない、または子供に適していないので除外してください。
{disallow_list}"""

prompt = f"""{metaprompt}
フランスのパリにある凱旋門を夕暮れの光の中で描き、
小さな子供がテディベアを持って見つめている様子の
画像を生成してください。
""""

try:
    # 画像生成APIを使用して画像を作成
    generation_response = openai.Image.create(
        prompt=prompt,    # ここにプロンプト・テキストを入力
        size='1024x1024',
        n=2,
        temperature=0,
    )
    # 保存する画像のディレクトリを設定
    image_dir = os.path.join(os.curdir, 'images')

    # ディレクトリが存在しない場合は作成
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)

    # 画像のパスを初期化（ファイル形式は png）
    image_path = os.path.join(image_dir, 'generated-image.png')

    # 生成された画像を取得
    image_url = generation_response["data"][0]["url"]  # レスポンスから画像URLを抽出
    generated_image = requests.get(image_url).content  # 画像をダウンロード
    with open(image_path, "wb") as image_file:
        image_file.write(generated_image)

    # デフォルトの画像ビューアで画像を表示
    image = Image.open(image_path)
    image.show()

# 例外をキャッチ
except openai.error.InvalidRequestError as err:
    print(err)
```

## お疲れ様でした!　学習を続ける

このレッスン修了後、[生成 AI 学習コレクション](https://aka.ms/genai-collection?WT.mc_id=academic-105485-yoterada) をチェックして、Generative AI の知識をレベルアップさせましょう。

次のレッスン 10 では、[ローコード AI アプリケーションの構築](../../../10-building-low-code-ai-applications/translations/ja-jp/README.md?WT.mc_id=academic-105485-yoterada)方法について学びます！
